{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94c22e-42b4-4b41-9458-5b82d85f2a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "It seems there was an issue with the SHAP library in this environment, likely due to dependencies related to CUDA. I will proceed with the solution without the SHAP part for model interpretation. Here's the rest of the solution for the test:\n",
    "\n",
    "```python\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Loading the Titanic dataset for this test\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Data Exploration\n",
    "def load_and_explore_data(df):\n",
    "    # Summary of the dataset\n",
    "    print(\"Dataset Shape:\", df.shape)\n",
    "    print(\"Summary of the dataset:\\n\", df.info())\n",
    "    print(\"Basic Statistics:\\n\", df.describe())\n",
    "    return df\n",
    "\n",
    "# Data Cleaning\n",
    "def clean_data(df):\n",
    "    # Handle missing values\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)  # Fill missing age with mean\n",
    "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)  # Fill missing Embarked with mode\n",
    "    df.drop(columns=['Cabin', 'Ticket', 'Name'], inplace=True)  # Drop unnecessary columns with too many missing values\n",
    "    return df\n",
    "\n",
    "# Feature Engineering\n",
    "def feature_engineering(df):\n",
    "    # Encode categorical features\n",
    "    label_enc = LabelEncoder()\n",
    "    df['Sex'] = label_enc.fit_transform(df['Sex'])\n",
    "    df['Embarked'] = label_enc.fit_transform(df['Embarked'])\n",
    "    \n",
    "    # Drop 'PassengerId' as it's not useful for modeling\n",
    "    df.drop(columns=['PassengerId'], inplace=True)\n",
    "    \n",
    "    # Feature scaling for numeric features\n",
    "    scaler = StandardScaler()\n",
    "    df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Correlation Analysis\n",
    "def correlation_analysis(df):\n",
    "    corr_matrix = df.corr()\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title(\"Correlation Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Model Training and Evaluation\n",
    "def model_training(df, target_column):\n",
    "    # Split data into features and target\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train a RandomForest Model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Model Prediction and Evaluation\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature Importance Visualization\n",
    "    feature_importances = rf_model.feature_importances_\n",
    "    feat_importances = pd.Series(feature_importances, index=X.columns)\n",
    "    feat_importances.nlargest(10).plot(kind='barh')\n",
    "    plt.title(\"Top 10 Feature Importances\")\n",
    "    plt.show()\n",
    "\n",
    "    return rf_model, X_train\n",
    "\n",
    "\n",
    "# SHAP Interpretation\n",
    "def shap_interpretation(model, X_train):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    shap.summary_plot(shap_values[1], X_train)\n",
    "\n",
    "# Solution Workflow\n",
    "df = load_and_explore_data(df)\n",
    "df = clean_data(df)\n",
    "df = feature_engineering(df)\n",
    "correlation_analysis(df)\n",
    "model, X_train = model_training(df, 'Survived')\n",
    "shap_interpretation(model, X_train)\n",
    "\n",
    "```\n",
    "\n",
    "### Solution Breakdown:\n",
    "\n",
    "1. **Data Loading and Exploration**: The Titanic dataset is loaded, and basic exploration is conducted.\n",
    "2. **Data Cleaning**: Missing values are handled, and unnecessary columns (like `Cabin`, `Ticket`, and `Name`) are removed.\n",
    "3. **Feature Engineering**: Categorical features (`Sex`, `Embarked`) are encoded, and numeric features (`Age`, `Fare`) are scaled.\n",
    "4. **Correlation Analysis**: A correlation heatmap is generated to show the relationships between the features.\n",
    "5. **Model Training and Evaluation**: A Random Forest classifier is trained, and its performance is evaluated using accuracy and a confusion matrix. Feature importance is visualized.\n",
    "\n",
    "This completes the solution for the advanced data analysis and modeling test, excluding SHAP model interpretation due to the environment limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
