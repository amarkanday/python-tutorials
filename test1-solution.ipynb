{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf0a478-3c45-4cfe-b42d-072fe4d2d130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Successfully loaded 1000 records.\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "    order_id customer_id  order_date product_id  quantity   price  \\\n",
      "0  ORD000001     CUST198  2022-04-21     PROD32         8  135.48   \n",
      "1  ORD000002      CUST67  2022-06-28     PROD70         5  184.73   \n",
      "2  ORD000003      CUST97  2023-08-28     PROD95         1  205.87   \n",
      "3  ORD000004      CUST71  2022-05-18     PROD64         4  191.79   \n",
      "4  ORD000005     CUST196  2022-03-14     PROD73         3  107.93   \n",
      "\n",
      "          category  \n",
      "0  Health & Beauty  \n",
      "1         Clothing  \n",
      "2    Home & Garden  \n",
      "3        Groceries  \n",
      "4         Clothing  \n",
      "\n",
      "Data types:\n",
      "order_id        object\n",
      "customer_id     object\n",
      "order_date      object\n",
      "product_id      object\n",
      "quantity         int64\n",
      "price          float64\n",
      "category        object\n",
      "dtype: object\n",
      "\n",
      "Missing values check:\n",
      "order_id       0\n",
      "customer_id    0\n",
      "order_date     0\n",
      "product_id     0\n",
      "quantity       0\n",
      "price          0\n",
      "category       0\n",
      "dtype: int64\n",
      "\n",
      "Converting order_date to datetime...\n",
      "After date conversion and extraction:\n",
      "    order_id customer_id order_date product_id  quantity   price  \\\n",
      "0  ORD000001     CUST198 2022-04-21     PROD32         8  135.48   \n",
      "1  ORD000002      CUST67 2022-06-28     PROD70         5  184.73   \n",
      "2  ORD000003      CUST97 2023-08-28     PROD95         1  205.87   \n",
      "3  ORD000004      CUST71 2022-05-18     PROD64         4  191.79   \n",
      "4  ORD000005     CUST196 2022-03-14     PROD73         3  107.93   \n",
      "\n",
      "          category  order_year  order_month order_yearmonth  \n",
      "0  Health & Beauty        2022            4         2022-04  \n",
      "1         Clothing        2022            6         2022-06  \n",
      "2    Home & Garden        2023            8         2023-08  \n",
      "3        Groceries        2022            5         2022-05  \n",
      "4         Clothing        2022            3         2022-03  \n",
      "\n",
      "Summary statistics for numerical columns:\n",
      "          quantity        price\n",
      "count  1000.000000  1000.000000\n",
      "mean      5.038000   250.653980\n",
      "std       2.577052   140.645065\n",
      "min       1.000000     6.180000\n",
      "25%       3.000000   133.437500\n",
      "50%       5.000000   246.255000\n",
      "75%       7.000000   372.712500\n",
      "max       9.000000   499.860000\n",
      "\n",
      "Creating total_sales feature...\n",
      "Sample data with total_sales:\n",
      "   quantity   price  total_sales\n",
      "0         8  135.48      1083.84\n",
      "1         5  184.73       923.65\n",
      "2         1  205.87       205.87\n",
      "3         4  191.79       767.16\n",
      "4         3  107.93       323.79\n",
      "\n",
      "After feature engineering:\n",
      "['order_id', 'customer_id', 'order_date', 'product_id', 'quantity', 'price', 'category', 'order_year', 'order_month', 'order_yearmonth', 'total_sales', 'customer_order_frequency', 'category_avg_price', 'product_popularity', 'order_day_of_week', 'is_month_end', 'season', 'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter', 'category_Clothing', 'category_Electronics', 'category_Groceries', 'category_Health & Beauty', 'category_Home & Garden']\n",
      "\n",
      "Training and testing data shape:\n",
      "X_train: (800, 17), X_test: (200, 17)\n",
      "y_train: (800,), y_test: (200,)\n",
      "\n",
      "Training Linear Regression model...\n",
      "\n",
      "Linear Regression Model Evaluation:\n",
      "Mean Squared Error (MSE): 113612.76\n",
      "Root Mean Squared Error (RMSE): 337.06\n",
      "R-squared (R²): 0.8834\n",
      "\n",
      "Training Random Forest model...\n",
      "\n",
      "Random Forest Model Evaluation:\n",
      "Mean Squared Error (MSE): 2368.60\n",
      "Root Mean Squared Error (RMSE): 48.67\n",
      "R-squared (R²): 0.9976\n",
      "\n",
      "Analysis and modeling completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set the style for visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# 1. Data Cleaning\n",
    "# Load the dataset\n",
    "print(\"Loading the dataset...\")\n",
    "try:\n",
    "    # Try loading the data from the provided file path\n",
    "    retail_data = pd.read_csv('./data/retail_data.csv')\n",
    "    print(f\"Successfully loaded {len(retail_data)} records.\")\n",
    "except:\n",
    "    # Generate random data if file loading fails\n",
    "    print(\"File not found, generating synthetic data...\")\n",
    "    # Generate random data\n",
    "    num_records = 1000\n",
    "    categories = ['Electronics', 'Clothing', 'Groceries', 'Home & Garden', 'Health & Beauty']\n",
    "    start_date = datetime(2022, 1, 1)\n",
    "    end_date = datetime(2024, 10, 1)\n",
    "\n",
    "    # Generate random data\n",
    "    data = {\n",
    "        'order_id': [f'ORD{str(i).zfill(6)}' for i in range(1, num_records + 1)],\n",
    "        'customer_id': [f'CUST{np.random.randint(1, 201)}' for _ in range(num_records)],\n",
    "        'order_date': [start_date + timedelta(days=np.random.randint(0, (end_date - start_date).days)) for _ in range(num_records)],\n",
    "        'product_id': [f'PROD{np.random.randint(1, 101)}' for _ in range(num_records)],\n",
    "        'quantity': np.random.randint(1, 10, size=num_records),\n",
    "        'price': np.round(np.random.uniform(5.0, 500.0, size=num_records), 2),\n",
    "        'category': [np.random.choice(categories) for _ in range(num_records)]\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame\n",
    "    retail_data = pd.DataFrame(data)\n",
    "    # Convert datetime objects to strings\n",
    "    retail_data['order_date'] = retail_data['order_date'].astype(str)\n",
    "    print(f\"Generated {len(retail_data)} records.\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(retail_data.head())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(retail_data.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values check:\")\n",
    "missing_values = retail_data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# If there are missing values, handle them\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"\\nHandling missing values...\")\n",
    "    # For numerical columns, fill with median\n",
    "    numerical_cols = retail_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in numerical_cols:\n",
    "        if retail_data[col].isnull().sum() > 0:\n",
    "            retail_data[col] = retail_data[col].fillna(retail_data[col].median())\n",
    "    \n",
    "    # For categorical columns, fill with mode\n",
    "    categorical_cols = retail_data.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if retail_data[col].isnull().sum() > 0 and col != 'order_date':\n",
    "            retail_data[col] = retail_data[col].fillna(retail_data[col].mode()[0])\n",
    "    \n",
    "    # For order_date, fill with previous date\n",
    "    if 'order_date' in retail_data.columns and retail_data['order_date'].isnull().sum() > 0:\n",
    "        retail_data['order_date'] = retail_data['order_date'].fillna(method='ffill')\n",
    "\n",
    "    print(\"After handling missing values:\")\n",
    "    print(retail_data.isnull().sum())\n",
    "\n",
    "# Convert order_date to datetime\n",
    "print(\"\\nConverting order_date to datetime...\")\n",
    "retail_data['order_date'] = pd.to_datetime(retail_data['order_date'])\n",
    "\n",
    "# Extract year and month into new columns\n",
    "retail_data['order_year'] = retail_data['order_date'].dt.year\n",
    "retail_data['order_month'] = retail_data['order_date'].dt.month\n",
    "retail_data['order_yearmonth'] = retail_data['order_date'].dt.strftime('%Y-%m')\n",
    "\n",
    "print(\"After date conversion and extraction:\")\n",
    "print(retail_data.head())\n",
    "\n",
    "# 2. Exploratory Data Analysis (EDA)\n",
    "# Generate summary statistics for numerical columns\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "print(retail_data[['quantity', 'price']].describe())\n",
    "\n",
    "# Distribution of sales by product category\n",
    "plt.figure(figsize=(12, 6))\n",
    "category_counts = retail_data['category'].value_counts()\n",
    "sns.barplot(x=category_counts.index, y=category_counts.values)\n",
    "plt.title('Distribution of Products by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Products')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('category_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Feature Engineering\n",
    "# Create a new feature called total_sales which is calculated as quantity * price\n",
    "print(\"\\nCreating total_sales feature...\")\n",
    "retail_data['total_sales'] = retail_data['quantity'] * retail_data['price']\n",
    "print(\"Sample data with total_sales:\")\n",
    "print(retail_data[['quantity', 'price', 'total_sales']].head())\n",
    "\n",
    "# Create additional features that might be relevant for predicting future sales\n",
    "# Customer order frequency\n",
    "customer_order_counts = retail_data.groupby('customer_id')['order_id'].count()\n",
    "retail_data['customer_order_frequency'] = retail_data['customer_id'].map(customer_order_counts)\n",
    "\n",
    "# Average price per category\n",
    "category_avg_price = retail_data.groupby('category')['price'].mean()\n",
    "retail_data['category_avg_price'] = retail_data['category'].map(category_avg_price)\n",
    "\n",
    "# Product popularity (number of times ordered)\n",
    "product_popularity = retail_data.groupby('product_id')['order_id'].count()\n",
    "retail_data['product_popularity'] = retail_data['product_id'].map(product_popularity)\n",
    "\n",
    "# Day of week\n",
    "retail_data['order_day_of_week'] = retail_data['order_date'].dt.dayofweek\n",
    "\n",
    "# Month-end flag (1 if the order was placed in the last 5 days of the month)\n",
    "retail_data['is_month_end'] = ((retail_data['order_date'].dt.day >= 25) & \n",
    "                              (retail_data['order_date'].dt.day <= 31)).astype(int)\n",
    "\n",
    "# Season\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "retail_data['season'] = retail_data['order_month'].apply(get_season)\n",
    "\n",
    "# One-hot encode the season\n",
    "season_dummies = pd.get_dummies(retail_data['season'], prefix='season')\n",
    "retail_data = pd.concat([retail_data, season_dummies], axis=1)\n",
    "\n",
    "# One-hot encode the category\n",
    "category_dummies = pd.get_dummies(retail_data['category'], prefix='category')\n",
    "retail_data = pd.concat([retail_data, category_dummies], axis=1)\n",
    "\n",
    "print(\"\\nAfter feature engineering:\")\n",
    "print(retail_data.columns.tolist())\n",
    "\n",
    "# Monthly sales trend\n",
    "monthly_sales = retail_data.groupby('order_yearmonth')['total_sales'].sum().reset_index()\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.lineplot(x='order_yearmonth', y='total_sales', data=monthly_sales, marker='o')\n",
    "plt.title('Monthly Sales Trend')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('monthly_sales_trend.png')\n",
    "plt.close()\n",
    "\n",
    "# Identify the top 5 products by total sales\n",
    "top_products = retail_data.groupby('product_id')['total_sales'].sum().reset_index()\n",
    "top_products = top_products.sort_values('total_sales', ascending=False).head(5)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='product_id', y='total_sales', data=top_products)\n",
    "plt.title('Top 5 Products by Total Sales')\n",
    "plt.xlabel('Product ID')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.tight_layout()\n",
    "plt.savefig('top_products.png')\n",
    "plt.close()\n",
    "\n",
    "# Sales by category\n",
    "category_sales = retail_data.groupby('category')['total_sales'].sum().reset_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='category', y='total_sales', data=category_sales)\n",
    "plt.title('Total Sales by Product Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('category_sales.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. Modeling\n",
    "# Define features to use in the model\n",
    "features = [\n",
    "    'quantity', 'price', 'customer_order_frequency', 'category_avg_price',\n",
    "    'product_popularity', 'order_day_of_week', 'is_month_end',\n",
    "    'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter',\n",
    "]\n",
    "\n",
    "# Add category dummies to features\n",
    "category_dummy_cols = [col for col in retail_data.columns if col.startswith('category_')]\n",
    "features.extend(category_dummy_cols)\n",
    "\n",
    "# Define the target\n",
    "target = 'total_sales'\n",
    "\n",
    "# Prepare the data\n",
    "X = retail_data[features]\n",
    "y = retail_data[target]\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTraining and testing data shape:\")\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# Linear Regression Model\n",
    "print(\"\\nTraining Linear Regression model...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"\\nLinear Regression Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_lr:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_lr:.2f}\")\n",
    "print(f\"R-squared (R²): {r2_lr:.4f}\")\n",
    "\n",
    "# Random Forest Model\n",
    "print(\"\\nTraining Random Forest model...\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_rf:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_rf:.2f}\")\n",
    "print(f\"R-squared (R²): {r2_rf:.4f}\")\n",
    "\n",
    "# Feature importance (for Random Forest)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Top 10 Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "# Actual vs. Predicted Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.title('Actual vs. Predicted Sales (Random Forest)')\n",
    "plt.xlabel('Actual Sales')\n",
    "plt.ylabel('Predicted Sales')\n",
    "plt.tight_layout()\n",
    "plt.savefig('actual_vs_predicted.png')\n",
    "plt.close()\n",
    "\n",
    "# Correlation matrix of numerical features\n",
    "correlation_matrix = retail_data[['quantity', 'price', 'total_sales', \n",
    "                                 'customer_order_frequency', 'category_avg_price', \n",
    "                                 'product_popularity']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nAnalysis and modeling completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d16903a-53e1-4518-aa82-f8b1c83a0dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
