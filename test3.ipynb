{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nycXV2XcU0_z"
   },
   "source": [
    "**Python Test for Staff Data Scientist Position **\n",
    "\n",
    "This test assesses your skills in data analysis, data science, and machine learning at an intermediate/advanced level using Python. Please provide clear and concise code, along with explanations and interpretations where necessary.\n",
    "\n",
    "**Dataset:**\n",
    "\n",
    "For this test, you'll be working with a synthetic dataset simulating sales data for a retailer. You can generate this dataset yourself using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_lU_a6dwU0_2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "n_rows = 10000\n",
    "df = pd.DataFrame({\n",
    "    'Store_ID': np.random.randint(1, 100, n_rows),\n",
    "    'Date': pd.to_datetime(np.random.choice(pd.date_range('2023-01-01', '2024-03-31'), n_rows)),\n",
    "    'Department': np.random.choice(['Electronics', 'Clothing', 'Grocery', 'Home Goods'], n_rows),\n",
    "    'Product_Category': np.random.choice(['TVs', 'Shirts', 'Produce', 'Furniture', 'Laptops', 'Pants', 'Dairy', 'Kitchenware'], n_rows),\n",
    "    'Units_Sold': np.random.randint(1, 50, n_rows),\n",
    "    'Price_per_Unit': np.random.uniform(5, 200, n_rows),\n",
    "    'Promotion': np.random.choice([True, False], n_rows),\n",
    "    'Holiday': np.random.choice([True, False], n_rows, p=[0.1, 0.9]),\n",
    "    'Temperature': np.random.uniform(20, 90, n_rows),\n",
    "    'Fuel_Price': np.random.uniform(2.5, 5, n_rows)\n",
    "})\n",
    "\n",
    "# Calculate total sales\n",
    "df['Total_Sales'] = df['Units_Sold'] * df['Price_per_Unit']\n",
    "\n",
    "# Save the dataset\n",
    "df.to_csv('sales_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHa5avq3U0_4"
   },
   "source": [
    "**Tasks:**\n",
    "\n",
    "1. **Data Loading and Exploration (10 points)**\n",
    "    * Load the dataset into a pandas DataFrame.\n",
    "    * Display the first 5 rows and all columns by `df.head()`.\n",
    "    * Show columns and their types by `df.info()`.\n",
    "    * Provide descriptive statistics of the numerical features.\n",
    "\n",
    "\n",
    "2. **Data Cleaning and Preprocessing (15 points)**\n",
    "    * Check for missing values in each column. If any are present, handle them with an appropriate imputation technique.\n",
    "    * Convert categorical variables ('Department', 'Product_Category', 'Promotion', 'Holiday') into numerical representations using one-hot encoding.\n",
    "    * Split the data into features (X) and target variable (y), where 'Total_Sales' is the target.\n",
    "\n",
    "\n",
    "3. **Exploratory Data Analysis (25 points)**\n",
    "    * Analyze the distribution of 'Total_Sales'.\n",
    "    * Explore the relationship between 'Total_Sales' and categorical features ('Department', 'Product_Category', 'Promotion', 'Holiday') using visualizations.\n",
    "    * Investigate the correlation between 'Total_Sales' and numerical features ('Units_Sold', 'Price_per_Unit', 'Temperature', 'Fuel_Price').\n",
    "    * Identify any trends or patterns in sales over time ('Date').\n",
    "\n",
    "\n",
    "4. **Feature Engineering (15 points)**\n",
    "    * Create new features that you believe could improve model performance. Justify your choices.\n",
    "    * Examples:\n",
    "        * `Weekend`: Whether the date is on a weekend.\n",
    "        * `Month`: Month of the year from the date.\n",
    "        * `Lagged_Sales`: Sales from the previous week or month.\n",
    "        * `Price_per_Unit_Discount`: Calculate discount percentage if `Promotion` is True.\n",
    "\n",
    "\n",
    "5. **Model Building and Evaluation (25 points)**\n",
    "    * Choose an appropriate machine learning model for predicting 'Total_Sales'. Consider regression models like Linear Regression, Decision Tree, Random Forest, or Gradient Boosting.\n",
    "    * Split the data into training and testing sets.\n",
    "    * Train the chosen model and tune hyperparameters using cross-validation or a similar technique.\n",
    "    * Evaluate the model's performance on the test set using relevant metrics (e.g., R-squared, Mean Squared Error, Root Mean Squared Error).\n",
    "\n",
    "\n",
    "6. **Model Interpretability and Insights (10 points)**\n",
    "    * If applicable, interpret the model's results. Which features are most important for predicting 'Total_Sales'?\n",
    "    * Provide actionable insights based on your analysis and model predictions that could be useful.\n",
    "\n",
    "\n",
    "**Bonus (10 points)**\n",
    "\n",
    "* Deploy your trained model as a simple API endpoint using a framework like Flask or FastAPI. This allows for model predictions on new data.\n",
    "\n",
    "**Submission:**\n",
    "\n",
    "Please submit your completed test as a Jupyter Notebook or a Python script. Include your code, explanations, visualizations, and interpretations.\n",
    "\n",
    "This test is designed to be challenging but also to showcase your abilities. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVzjfLGtVv8L",
    "outputId": "fac7663f-bc92-447d-aa1a-c1e407f137cc"
   },
   "outputs": [],
   "source": [
    "## Load the dataset into a pandas DataFrame.\n",
    "\n",
    "## Display the first 5 rows and all columns by df.head().\n",
    "\n",
    "## Show columns and their types by df.info().\n",
    "\n",
    "## Provide descriptive statistics of the numerical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "id": "9eac5MZ6WYdJ",
    "outputId": "cbe06e05-818d-48c4-ff79-7d3c8343fb61"
   },
   "outputs": [],
   "source": [
    "## Check for missing values in each column. If any are present, handle them with an appropriate imputation technique.\n",
    "\n",
    "## Convert categorical variables ('Department', 'Product_Category', 'Promotion', 'Holiday') into numerical representations using one-hot encoding.\n",
    "\n",
    "## Split the data into features (X) and target variable (y), where 'Total_Sales' is the target.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8lA36N05ZPzb",
    "outputId": "f482d981-9eac-4d8b-a598-4ce2332d43a1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "## Analyze the distribution of 'Total_Sales'.\n",
    "\n",
    "## Explore the relationship between 'Total_Sales' and categorical features ('Department', 'Product_Category', 'Promotion', 'Holiday') using visualizations.\n",
    "\n",
    "## Investigate the correlation between 'Total_Sales' and numerical features ('Units_Sold', 'Price_per_Unit', 'Temperature', 'Fuel_Price').\n",
    "\n",
    "\n",
    "## Identify any trends or patterns in sales over time ('Date')\n",
    "\n",
    "\n",
    "## Create new features that you believe could improve model performance. Justify your choices.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRjVPvCslPpb"
   },
   "outputs": [],
   "source": [
    "# Choose an appropriate machine learning model for predicting 'Total_Sales'. Consider regression models like Linear Regression, Decision Tree, Random Forest, or Gradient Boosting.\n",
    "# Split the data into training and testing sets.\n",
    "# Train the chosen model and tune hyperparameters using cross-validation or a similar technique.\n",
    "# Evaluate the model's performance on the test set using relevant metrics (e.g., R-squared, Mean Squared Error, Root Mean Squared Error)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
